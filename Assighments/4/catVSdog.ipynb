{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "catVSdog.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMFizlSayZ3H/whJ12HvEo6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alirez1043/DeepLearning/blob/main/Assighments/4/catVSdog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQBcspJVe4vS",
        "outputId": "a1230cf6-0f4c-467b-9195-77630118a985"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "68608000/68606236 [==============================] - 1s 0us/step\n",
            "68616192/68606236 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "\n",
        "train_dir =  \"/root/.keras/datasets/cats_and_dogs_filtered/train\"\n",
        "validation_dir = \"/root/.keras/datasets/cats_and_dogs_filtered/validation\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.data.Dataset.list_files(str(train_dir+'/*/*'))\n",
        "val_ds = tf.data.Dataset.list_files(str(validation_dir+'/*/*'))"
      ],
      "metadata": {
        "id": "0Dya5qJnfEUl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Examples of Train Path :\")\n",
        "for path in train_ds.take(2):\n",
        "  print(path)\n",
        "\n",
        "print(\"\\nExamples of Validation path :\")\n",
        "for path in val_ds.take(2) :\n",
        "  print(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6ICoGHPfcFd",
        "outputId": "c7710e12-8d1e-43ec-c2d7-48d3ca843532"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examples of Train Path :\n",
            "tf.Tensor(b'/root/.keras/datasets/cats_and_dogs_filtered/train/cats/cat.550.jpg', shape=(), dtype=string)\n",
            "tf.Tensor(b'/root/.keras/datasets/cats_and_dogs_filtered/train/dogs/dog.592.jpg', shape=(), dtype=string)\n",
            "\n",
            "Examples of Validation path :\n",
            "tf.Tensor(b'/root/.keras/datasets/cats_and_dogs_filtered/validation/cats/cat.2176.jpg', shape=(), dtype=string)\n",
            "tf.Tensor(b'/root/.keras/datasets/cats_and_dogs_filtered/validation/dogs/dog.2112.jpg', shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_labeled_data(path):\n",
        "  class_names = tf.constant(['cat', 'dog'])\n",
        "\n",
        "  categorical_label = tf.strings.split(path, '/')[-1]\n",
        "  categorical_label = tf.strings.split(categorical_label, '.')[0]\n",
        "  label = tf.cast(categorical_label == class_names[0], tf.int8) # cat=1, dog=0\n",
        "  image = tf.io.read_file(path)\n",
        "  image = tf.image.decode_image( image, expand_animations=False )\n",
        "  \n",
        "  return image, label"
      ],
      "metadata": {
        "id": "C8DEjOONf_5B"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalization(img):\n",
        "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "  return img / 255"
      ],
      "metadata": {
        "id": "8BYVgvYNguO0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_data(image):\n",
        "    image = tf.image.resize_with_crop_or_pad(image, 180, 180) # Add 6 pixels of padding\n",
        "    image = tf.image.random_crop(image, size=[150, 150, 3]) # Random crop back to 28x28\n",
        "    image = tf.image.random_brightness(image, max_delta=0.5) # Random brightness\n",
        "    image = tf.image.flip_left_right(image)\n",
        "    return image"
      ],
      "metadata": {
        "id": "_YPCyf9EhSqi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image_train(path) :\n",
        "    image  ,label = prepare_labeled_data(path)\n",
        "    image = augment_data(image)\n",
        "    image = normalization(image)\n",
        "    return image  ,label\n",
        "\n",
        "def load_image_test(path) :\n",
        "    image, label = prepare_labeled_data(path)\n",
        "    image = tf.image.resize(image, [150, 150])\n",
        "    image = normalization(image)\n",
        "    return image, label"
      ],
      "metadata": {
        "id": "4WPvQbrehgFF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE=64\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "BUFFER_SIZE=1000"
      ],
      "metadata": {
        "id": "U_We9756k7lp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_ds.map(load_image_train).shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "val_ds = val_ds.map(load_image_test).batch(BATCH_SIZE).prefetch(AUTOTUNE)"
      ],
      "metadata": {
        "id": "J3JUip5HlDm4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Instances of train images :\")\n",
        "for img, lbl in train_ds.take(1):\n",
        "  print(img[0] ,\"   \" ,lbl[0])\n",
        "print(\"\\ninstances of validation images :\")\n",
        "for img, lbl in val_ds.take(1):\n",
        "  print(img[0] ,\"   \" ,lbl[0])"
      ],
      "metadata": {
        "id": "cTN4zIJalSlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv2DBlock(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_filters ,activation = 'relu'  ,padding = 'valid',**kwargs) :\n",
        "    super(Conv2DBlock ,self).__init__(**kwargs)\n",
        "    self.conv2d = tf.keras.layers.Conv2D(num_filters ,(3,3),padding = padding ,activation = activation)\n",
        "    self.maxPool2D = tf.keras.layers.MaxPool2D((2,2))\n",
        "\n",
        "  def call(self ,input) :\n",
        "    Z = input\n",
        "    Z = self.conv2d(Z)\n",
        "    Z = self.maxPool2D(Z)\n",
        "    return Z "
      ],
      "metadata": {
        "id": "obm00OY5uWRv"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyCustomModel(tf.keras.models.Model):\n",
        "  def __init__(self ,activation = 'relu' ,**kwargs):\n",
        "    super(MyCustomModel ,self).__init__(**kwargs)\n",
        "    self.blocks = [\n",
        "                   Conv2DBlock(32),\n",
        "                   Conv2DBlock(64),\n",
        "                   Conv2DBlock(128),\n",
        "                   Conv2DBlock(128)\n",
        "                  ]\n",
        "    self.model_layers = [\n",
        "                   tf.keras.layers.Flatten(),\n",
        "                   tf.keras.layers.Dropout(0.2),\n",
        "                   tf.keras.layers.Dense(512, activation=activation),\n",
        "                   tf.keras.layers.Dense(128 ,activation = activation),\n",
        "                   tf.keras.layers.Dense(1),\n",
        "                   tf.keras.layers.Activation('sigmoid')\n",
        "                  ]\n",
        "  def call(self ,input) :\n",
        "    Z = input\n",
        "    for block in self.blocks :\n",
        "      Z = block(Z)\n",
        "    for layer in self.model_layers :\n",
        "      Z = layer(Z)\n",
        "    return Z "
      ],
      "metadata": {
        "id": "56VQNAruA2Kr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_model = MyCustomModel()"
      ],
      "metadata": {
        "id": "YLKCeiR1FwwV"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "QztXmO--F1UJ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = my_model.fit(train_ds, \n",
        "                    epochs=25,\n",
        "                    validation_data=val_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdpLDo0NGFl8",
        "outputId": "ea55582f-02e1-4f04-ee5e-e4bc1d25acc3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "32/32 [==============================] - 12s 227ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6974 - val_accuracy: 0.5000\n",
            "Epoch 2/25\n",
            "32/32 [==============================] - 8s 191ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6975 - val_accuracy: 0.5000\n",
            "Epoch 3/25\n",
            "32/32 [==============================] - 8s 193ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6974 - val_accuracy: 0.5000\n",
            "Epoch 4/25\n",
            "32/32 [==============================] - 9s 193ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6975 - val_accuracy: 0.5000\n",
            "Epoch 5/25\n",
            "32/32 [==============================] - 8s 192ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6975 - val_accuracy: 0.5000\n",
            "Epoch 6/25\n",
            "32/32 [==============================] - 8s 193ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6975 - val_accuracy: 0.5000\n",
            "Epoch 7/25\n",
            "32/32 [==============================] - 8s 195ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6976 - val_accuracy: 0.5000\n",
            "Epoch 8/25\n",
            "32/32 [==============================] - 8s 191ms/step - loss: 0.6932 - accuracy: 0.4970 - val_loss: 0.6976 - val_accuracy: 0.5000\n",
            "Epoch 9/25\n",
            "32/32 [==============================] - 8s 193ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6977 - val_accuracy: 0.5000\n",
            "Epoch 10/25\n",
            "32/32 [==============================] - 9s 195ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6976 - val_accuracy: 0.5000\n",
            "Epoch 11/25\n",
            "32/32 [==============================] - 9s 194ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6976 - val_accuracy: 0.5000\n",
            "Epoch 12/25\n",
            "32/32 [==============================] - 8s 193ms/step - loss: 0.6932 - accuracy: 0.4880 - val_loss: 0.6976 - val_accuracy: 0.5000\n",
            "Epoch 13/25\n",
            "32/32 [==============================] - 8s 192ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6976 - val_accuracy: 0.5000\n",
            "Epoch 14/25\n",
            "32/32 [==============================] - 8s 192ms/step - loss: 0.6932 - accuracy: 0.4920 - val_loss: 0.6975 - val_accuracy: 0.5000\n",
            "Epoch 15/25\n",
            "32/32 [==============================] - 8s 193ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6975 - val_accuracy: 0.5000\n",
            "Epoch 16/25\n",
            "32/32 [==============================] - 8s 193ms/step - loss: 0.6932 - accuracy: 0.4920 - val_loss: 0.6976 - val_accuracy: 0.5000\n",
            "Epoch 17/25\n",
            "32/32 [==============================] - 8s 192ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6976 - val_accuracy: 0.5000\n",
            "Epoch 18/25\n",
            "32/32 [==============================] - 9s 194ms/step - loss: 0.6932 - accuracy: 0.4830 - val_loss: 0.6976 - val_accuracy: 0.5000\n",
            "Epoch 19/25\n",
            "32/32 [==============================] - 8s 194ms/step - loss: 0.6932 - accuracy: 0.4950 - val_loss: 0.6975 - val_accuracy: 0.5000\n",
            "Epoch 20/25\n",
            "32/32 [==============================] - 8s 195ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6975 - val_accuracy: 0.5000\n",
            "Epoch 21/25\n",
            "32/32 [==============================] - 9s 195ms/step - loss: 0.6932 - accuracy: 0.4900 - val_loss: 0.6976 - val_accuracy: 0.5000\n",
            "Epoch 22/25\n",
            "32/32 [==============================] - 8s 191ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6976 - val_accuracy: 0.5000\n",
            "Epoch 23/25\n",
            "32/32 [==============================] - 8s 193ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6977 - val_accuracy: 0.5000\n",
            "Epoch 24/25\n",
            "32/32 [==============================] - 8s 192ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6977 - val_accuracy: 0.5000\n",
            "Epoch 25/25\n",
            "32/32 [==============================] - 9s 196ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6979 - val_accuracy: 0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6I0R83wvGLW5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}